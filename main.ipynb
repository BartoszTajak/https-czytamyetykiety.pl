{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BartoszTajak/https-czytamyetykiety.pl/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3fd937",
      "metadata": {
        "id": "7b3fd937"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import math\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to current website\n",
        "base_link = r'https://czytamyetykiety.pl/producenci-zywnosci/'\n",
        "r = requests.get(base_link)\n",
        "soup = bs(r.content, \"html.parser\")\n",
        "#list of all tabs (A,B,C...)\n",
        "all_tabs = soup.find_all('ul', {'class': 'css-pub6cd e1vaxell7'})[0].select('li')\n",
        "all_tabs =['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','Q','P','R','S','T','U','V','W','X','Y','Z']\n",
        "    \n",
        "\n",
        "\n",
        "# page by page  (A,B,C....)\n",
        "for lettter in all_tabs:\n",
        "    link = f'https://czytamyetykiety.pl/producenci-zywnosci/?letter={lettter}'\n",
        "    r = requests.get(link)\n",
        "    soup = bs(r.content, \"html.parser\")\n",
        "    companies = soup.find_all('ul', {'class': 'css-1xoq838 e1vaxell1'})[0].select('li')\n",
        "    # create empty DataFrame\n",
        "    df = pd.DataFrame()\n",
        "    # all brands on page \n",
        "    for i in companies:\n",
        "        try:\n",
        "            data_to_frame=[]\n",
        "            print('Następny producent : ',i.get_text())\n",
        "            # add to producer's list\n",
        "            Producent = i.get_text()\n",
        "\n",
        "            href = i.find('a').attrs['href']\n",
        "            company_link='https://czytamyetykiety.pl'+href\n",
        "            time.sleep(1)\n",
        "\n",
        "\n",
        "            r = requests.get(company_link)\n",
        "            soup = bs(r.content, \"html.parser\")\n",
        "            all_products = soup.find_all('div', {'class': 'row css-xqnzc8 e1jjiacg7'})[0]\n",
        "            lenght = len(all_products.find_all('a' , {'class' : 'css-1ri2k5u ejmlxjt3'}))\n",
        "            # all items on page \n",
        "            for y in range(lenght):\n",
        "                main_list = []\n",
        "                try:\n",
        "                    main_list.append(Producent)\n",
        "                    every_item = all_products.find_all('a' , {'class' : 'css-1ri2k5u ejmlxjt3'})[y].attrs['href']\n",
        "\n",
        "                    # link to each iteam \n",
        "                    link_to_product = 'https://czytamyetykiety.pl'+every_item\n",
        "                    r = requests.get(link_to_product)\n",
        "                    soup = bs(r.content, \"html.parser\")\n",
        "                    every_item = soup.find_all('ul', {'class': 'css-1dwqukr eq13dfd10'})[0].select('li')\n",
        "\n",
        "\n",
        "                    name_of_product = soup.find('h1' , {'class' : 'css-3ro1ko eq13dfd5'})\n",
        "                    Produkt = name_of_product.get_text()\n",
        "                    main_list.append(Produkt)\n",
        "                    lista_skaldnikow = []\n",
        "                    for x in every_item:\n",
        "                        skladnik = x.get_text()\n",
        "                        lista_skaldnikow.append(skladnik)\n",
        "\n",
        "                    every_item = soup.find_all('div', {'class': 'css-12npjva e1sc61rg3'})[0]\n",
        "                    if every_item.find('div' , {'class' : 'css-6sex43'}) != None:\n",
        "                        ocena = 'Produkt sredni'\n",
        "                    elif every_item.find('div' , {'class' : 'css-jtr8y8'}) != None:\n",
        "                        ocena = 'Produkt dobry'\n",
        "                    else:\n",
        "                        ocena = 'Produkt zly'\n",
        "\n",
        "                    main_list.append(lista_skaldnikow)\n",
        "                    main_list.append(ocena)\n",
        "                    rr = requests.get(link_to_product)\n",
        "                    soup = bs(rr.content, \"html.parser\")\n",
        "                    bialko_weg_fett = []\n",
        "                    lenght = len(soup.find_all('ul', {'class': 'css-1w0253d eq13dfd8'})[0].find_all('div', {\n",
        "                        'class': 'row css-166ixqk els7ok21'}))\n",
        "                    for i in range(1, lenght - 1):\n",
        "                        name = soup.find_all('ul', {'class': 'css-1w0253d eq13dfd8'})[0].find_all('div', {\n",
        "                            'class': 'row css-166ixqk els7ok21'})[i].select('div')[0].get_text()\n",
        "                        value = soup.find_all('ul', {'class': 'css-1w0253d eq13dfd8'})[0].find_all('div', {\n",
        "                            'class': 'row css-166ixqk els7ok21'})[i].select('div')[1].get_text()\n",
        "                        bialko_weg_fett.append(name)\n",
        "                        bialko_weg_fett.append(value)\n",
        "\n",
        "                    main_list.append(bialko_weg_fett)\n",
        "\n",
        "                    # Adding extra inf ( slodyczne , napoje etc...)\n",
        "                    all_tabs = soup.find_all('ol', {'class': 'css-1ifqhry eir1p9f2'})[0].select('li')\n",
        "                    len(all_tabs)\n",
        "                    artykow = len(all_tabs) - 2\n",
        "                    all_tabs = soup.find_all('ol', {'class': 'css-1ifqhry eir1p9f2'})[0].select('li')[artykow]\n",
        "                    all_tabs.get_text()\n",
        "                    main_list.append(all_tabs.get_text())\n",
        "\n",
        "                    # Adding extra inf ( produkt weganski etc...)\n",
        "                    all_tabs = soup.find_all('div', {'class': 'row css-be81vk e1sc61rg2'})[0].find_all('span',{'data-tip': True})\n",
        "                    extra_lista=[]\n",
        "                    for i in all_tabs:\n",
        "                        extra_lista.append(i['data-tip'])\n",
        "\n",
        "                    main_list.append(extra_lista)\n",
        "\n",
        "                except:\n",
        "                    print('error')\n",
        "\n",
        "\n",
        "                print(main_list)\n",
        "                data_to_frame.append(main_list)\n",
        "                main_list=[]\n",
        "\n",
        "\n",
        "\n",
        "            for i in data_to_frame:\n",
        "                if len(i) == 7 :\n",
        "                    df2 = pd.DataFrame([i], columns=['Producent', 'Produkt', 'Sklad','Jakosc produktu', 'Wartosc odrz.','Kategoria', 'Extra inf.'])\n",
        "                    df = df.concat(df2)\n",
        "                    df.to_csv(f'{Producent}.csv', sep=';', index=False, encoding='utf-8-sig')\n",
        "                else:\n",
        "                    print('error niezgodna ilosc skladników')\n",
        "\n",
        "        except:\n",
        "            print('some error')\n",
        "\n",
        "\n",
        "    link = f'https://czytamyetykiety.pl/producenci-zywnosci/?letter={lettter}'\n",
        "    r = requests.get(link)\n",
        "    soup = bs(r.content, \"html.parser\")\n",
        "    companies = soup.find_all('ul', {'class': 'css-1xoq838 e1vaxell1'})[0].select('li')\n",
        "    if len(companies)==51:\n",
        "\n",
        "        link = f'https://czytamyetykiety.pl/producenci-zywnosci/page/2/?letter={lettter}'\n",
        "        r = requests.get(link)\n",
        "        soup = bs(r.content, \"html.parser\")\n",
        "        companies = soup.find_all('ul', {'class': 'css-1xoq838 e1vaxell1'})[0].select('li')\n",
        "        for i in companies:\n",
        "            try:\n",
        "                data_to_frame = []\n",
        "                print('Następny producent : ', i.get_text())\n",
        "                # add to producer's list\n",
        "                Producent = i.get_text()\n",
        "\n",
        "                href = i.find('a').attrs['href']\n",
        "                company_link = 'https://czytamyetykiety.pl' + href\n",
        "                time.sleep(1)\n",
        "\n",
        "\n",
        "                r = requests.get(company_link)\n",
        "                soup = bs(r.content, \"html.parser\")\n",
        "                all_products = soup.find_all('div', {'class': 'row css-xqnzc8 e1jjiacg7'})[0]\n",
        "                lenght = len(all_products.find_all('a', {'class': 'css-1ri2k5u ejmlxjt3'}))\n",
        "                # all products on page\n",
        "                for y in range(lenght):\n",
        "                    main_list = []\n",
        "                    try:\n",
        "                        main_list.append(Producent)\n",
        "                        every_item = all_products.find_all('a', {'class': 'css-1ri2k5u ejmlxjt3'})[y].attrs['href']\n",
        "\n",
        "                        # link to every item on page\n",
        "                        link_to_product = 'https://czytamyetykiety.pl' + every_item\n",
        "                        r = requests.get(link_to_product)\n",
        "                        soup = bs(r.content, \"html.parser\")\n",
        "                        every_item = soup.find_all('ul', {'class': 'css-1dwqukr eq13dfd10'})[0].select('li')\n",
        "\n",
        "                        name_of_product = soup.find('h1', {'class': 'css-3ro1ko eq13dfd5'})\n",
        "                        Produkt = name_of_product.get_text()\n",
        "                        main_list.append(Produkt)\n",
        "                        lista_skaldnikow = []\n",
        "                        for x in every_item:\n",
        "\n",
        "                            skladnik = x.get_text()\n",
        "                            lista_skaldnikow.append(skladnik)\n",
        "\n",
        "\n",
        "                        every_item = soup.find_all('div', {'class': 'css-12npjva e1sc61rg3'})[0]\n",
        "                        if every_item.find('div', {'class': 'css-6sex43'}) != None:\n",
        "                            ocena = 'Produkt sredni'\n",
        "                        elif every_item.find('div', {'class': 'css-jtr8y8'}) != None:\n",
        "                            ocena = 'Produkt dobry'\n",
        "                        else:\n",
        "                            ocena = 'Produkt zly'\n",
        "\n",
        "                        main_list.append(lista_skaldnikow)\n",
        "                        main_list.append(ocena)\n",
        "                        rr = requests.get(link_to_product)\n",
        "                        soup = bs(rr.content, \"html.parser\")\n",
        "\n",
        "\n",
        "                        bialko_weg_fett=[]\n",
        "                        lenght = len(soup.find_all('ul', {'class': 'css-1w0253d eq13dfd8'})[0].find_all('div', {\n",
        "                            'class': 'row css-166ixqk els7ok21'}))\n",
        "                        for i in range(1, lenght - 1):\n",
        "                            name = soup.find_all('ul', {'class': 'css-1w0253d eq13dfd8'})[0].find_all('div', {\n",
        "                                'class': 'row css-166ixqk els7ok21'})[i].select('div')[0].get_text()\n",
        "                            value = soup.find_all('ul', {'class': 'css-1w0253d eq13dfd8'})[0].find_all('div', {\n",
        "                                'class': 'row css-166ixqk els7ok21'})[i].select('div')[1].get_text()\n",
        "                            bialko_weg_fett.append(name)\n",
        "                            bialko_weg_fett.append(value)\n",
        "\n",
        "\n",
        "                        main_list.append(bialko_weg_fett)\n",
        "\n",
        "                        # Dodawanie kategori ( slodyczne , napoje etc...)\n",
        "                        all_tabs = soup.find_all('ol', {'class': 'css-1ifqhry eir1p9f2'})[0].select('li')\n",
        "                        len(all_tabs)\n",
        "                        artykow = len(all_tabs) - 2\n",
        "                        all_tabs = soup.find_all('ol', {'class': 'css-1ifqhry eir1p9f2'})[0].select('li')[artykow]\n",
        "                        all_tabs.get_text()\n",
        "                        main_list.append(all_tabs.get_text())\n",
        "\n",
        "                        # Dodawanie dodatkowych inf ( produkt weganski etc...)\n",
        "                        all_tabs = soup.find_all('div', {'class': 'row css-be81vk e1sc61rg2'})[0].find_all('span', {\n",
        "                            'data-tip': True})\n",
        "                        extra_lista = []\n",
        "                        for i in all_tabs:\n",
        "                            extra_lista.append(i['data-tip'])\n",
        "\n",
        "                        main_list.append(extra_lista)\n",
        "\n",
        "                    except:\n",
        "                        print('error')\n",
        "\n",
        "\n",
        "                    print(main_list)\n",
        "                    data_to_frame.append(main_list)\n",
        "                    main_list = []\n",
        "\n",
        "                for i in data_to_frame:\n",
        "                    if len(i) == 7:\n",
        "                        df2 = pd.DataFrame([i],\n",
        "                                           columns=['Producent', 'Produkt', 'Sklad', 'Jakosc produktu', 'Wartosc odrz.',\n",
        "                                                    'Kategoria', 'Extra inf.'])\n",
        "                        df = df.append(df2)\n",
        "                        df.to_csv(f'{Producent}.csv', sep=';', index=False, encoding='utf-8-sig')\n",
        "                    else:\n",
        "                        print('error niezgodna ilosc skladników')\n",
        "\n",
        "            except:\n",
        "                print('some error')\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Kd_YNl1gajz"
      },
      "id": "3Kd_YNl1gajz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a15f158",
      "metadata": {
        "id": "0a15f158"
      },
      "outputs": [],
      "source": [
        "# create empty DataFrame\n",
        "all_product = pd.DataFrame()\n",
        "mypath = r'/content/drive/MyDrive/Python/czytamy_etykiety/csv'\n",
        "csv_list = os.listdir(mypath)\n",
        "# combain all csv files\n",
        "for i in csv_list:   \n",
        "    df = pd.read_csv(mypath+'//'+i, sep =';',encoding='utf-8')\n",
        "    all_product = pd.concat([all_product,df])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Division according to quality\n",
        "\n",
        "all_product = all_product.rename(columns={\"Jakosc produktu\": \"quality of product\"})\n",
        "quality=(all_product['quality of product'].value_counts()).to_dict()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.bar(*zip(*quality.items()))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9p2cDGt7lSH1"
      },
      "id": "9p2cDGt7lSH1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Division according to category\n",
        "\n",
        "lista = all_product['Kategoria'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(28,15))\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid()\n",
        "D = lista.to_dict()\n",
        "\n",
        "D_name = [i[0] for i in list(D.items()) if i[1] > 5 ] \n",
        "D_num = [i[1] for i in list(D.items()) if i[1] > 5 ] \n",
        "D = dict(zip(D_name, D_num))\n",
        "\n",
        "plt.bar(*zip(*D.items()))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rJRjoH2_Iw9Q"
      },
      "id": "rJRjoH2_Iw9Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new column with number of ingredients\n",
        "all_product['Nr. of  Ingredient'] = all_product['Sklad'].apply(lambda data: len(data.split(',')))"
      ],
      "metadata": {
        "id": "6c1suEET2MgL"
      },
      "id": "6c1suEET2MgL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting kcal/kj from data \n",
        "all_product['Energy'] = all_product['Wartosc odrz.'].str.extract(r'(\\d*\\s*kcal|\\d*\\s*Kcal|\\d*\\s*kj|\\d*\\s*Kj|\\d*\\s*kJ)')\n",
        "all_product['Energy'] = all_product['Energy'].astype(str)\n",
        "\n",
        "\n",
        "# clead data and change to kj \n",
        "def energia(x):\n",
        "  x = x.replace(' ','')\n",
        "  if (('kJ' in x )or('KJ' in x)) or ('kj' in x):\n",
        "    x = re.sub(\"(kj|KJ|kJ)\", \"\", x)\n",
        "    return x\n",
        "  elif ('Kcal' in x) or ('kcal' in x):\n",
        "    x = re.sub(\"(kcal|Kcal)\", \"\", x)\n",
        "    x = int(x)\n",
        "    return round(4.18*x,2)\n",
        "  else:\n",
        "    return x\n",
        "\n",
        "\n",
        "all_product['Energy'] = all_product['Energy'].apply(energia)\n",
        "\n",
        "\n",
        "# clead data from '' , 'nan'\n",
        "all_product.reset_index(inplace=True,drop=True)\n",
        "all_product.drop(all_product.index[all_product['Energy'] == ''], inplace = True)\n",
        "all_product.drop(all_product.index[all_product['Energy'] == 'nan'], inplace = True)\n",
        "all_product['Energy'] = all_product['Energy'].apply(lambda x : round(float(x) /4.18,2))\n",
        "all_product = all_product.drop(all_product[all_product['Energy'] >900].index)\n"
      ],
      "metadata": {
        "id": "8UDdE6JG6qiD"
      },
      "id": "8UDdE6JG6qiD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def value_extract(x):\n",
        "  if type(x) == str:\n",
        "    try:\n",
        "      x = x.replace(',','.')\n",
        "      x = x.replace(' ','')\n",
        "      return round(float(x),2)\n",
        "    except:\n",
        "      return 0\n",
        "\n",
        "# extracting protein,carbohydrates,fat from data \n",
        "\n",
        "all_product['protein'] = all_product['Wartosc odrz.'].str.extract(r'(..a.k..{1,5},.{1,5}\\d{1,3},*d{0,2})')\n",
        "\n",
        "all_product['carbohydrates'] = all_product['Wartosc odrz.'].str.extract(r'(glowodany.{1,12}\\d{1,3})')\n",
        "\n",
        "all_product['fat'] = all_product['Wartosc odrz.'].str.extract(r'(uszcz.{1,5},.{1,5}\\d{1,3},*d{0,2})')\n",
        "\n",
        "list_of_columns = ['protein','carbohydrates','fat']\n",
        "\n",
        "for column in list_of_columns:\n",
        "  all_product[column] = all_product[column].str.extract(r'(\\d{1,3},*\\d{0,3})')\n",
        "  all_product[column] = all_product[column].apply(value_extract)\n",
        "  all_product[column].fillna(0, inplace = True)\n",
        "  all_product[column]=all_product[column].astype(np.float16)\n",
        "  all_product[column]=all_product[column].apply(lambda x: round(x,1))\n",
        "\n",
        "\n",
        "\n",
        "all_product['Temp'] = all_product['protein'] + all_product['carbohydrates'] + all_product['fat']\n",
        "all_product = all_product.drop(all_product[all_product['Temp'] >100].index)\n",
        "all_product.drop(['Temp'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "HvN_Tc6XnUzh"
      },
      "id": "HvN_Tc6XnUzh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_product.reset_index(inplace=True,drop=True)\n",
        "all_product.to_excel('/content/drive/MyDrive/ALLES.xlsx')\n",
        "all_product"
      ],
      "metadata": {
        "id": "jDlzS_exsk0O"
      },
      "id": "jDlzS_exsk0O",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}